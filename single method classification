# -*- coding: utf-8 -*-
"""
Created on Sat Aug 22 00:26:41 2020

@author: 35453
"""

import numpy as np
import pandas as pd

data = pd.read_csv('data_after_preprocess.csv')

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(data.iloc[:,0:-1],data.iloc[:,-1],test_size=0.3,random_state=1)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)



# Fitting decision tree to the Training set
from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0,max_depth=8)
classifier.fit(X_train, Y_train)

# Predicting the Test set results
Y_pred = classifier.predict(X_test)

# CONFUSION MATRIX
from sklearn.metrics import confusion_matrix
cm_DT = confusion_matrix(Y_test, Y_pred)
# ACCURACY 
from sklearn.metrics import accuracy_score
accuracy_score_DT=accuracy_score(Y_test, Y_pred)
# PRECISION 
from sklearn.metrics import precision_score
precision_score_DT=precision_score(Y_test, Y_pred, average='weighted')
# RECALL
from sklearn.metrics import recall_score
recall_score_DT=recall_score(Y_test, Y_pred, average='weighted')
# F1 SCORE
from sklearn.metrics import f1_score
f1_score_DT=f1_score(Y_test, Y_pred, average='weighted')

# AUC + ROC CURVE
from sklearn.metrics import roc_curve, auc 
y_pred_proba =classifier.predict_proba(X_test)[:,1]
fpr,tpr,threshold = roc_curve(Y_test,y_pred_proba)
roc_auc_DT = auc(fpr,tpr) 

import matplotlib.pyplot as plt
plt.figure()
lw = 2
plt.figure(figsize=(10,10))
plt.plot(fpr, tpr, color='b',
         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc_DT) 
plt.plot([0, 1], [0, 1], color='y', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('decision tree with 8 layers ROC curve (AUC = %0.4f)' % roc_auc_DT,fontsize=18)
plt.legend(loc="lower right")
plt.show()


from sklearn import tree
X, y = X_train,Y_train
clf = tree.DecisionTreeClassifier(criterion = 'entropy', random_state = 0,max_depth=8)
clf = clf.fit(X, y)
plt.figure(figsize=(50,50))
tree.plot_tree(clf) 


# Fitting SVM classifier to the Training set
from sklearn.svm import SVC
classifier = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, 
                 probability=False, tol=0.001, cache_size=200, class_weight=None, 
                 verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False,
                 random_state=None)
classifier.fit(X_train, Y_train)

# Predicting the Test set results
Y_pred = classifier.predict(X_test)

# CONFUSION MATRIX
from sklearn.metrics import confusion_matrix
cm_SVM = confusion_matrix(Y_test, Y_pred)
# ACCURACY PROBABILITY
from sklearn.metrics import accuracy_score
accuracy_score_SVM=accuracy_score(Y_test, Y_pred)
# PRECISION 
from sklearn.metrics import precision_score
precision_score_SVM=precision_score(Y_test, Y_pred, average='weighted')
# RECALL
from sklearn.metrics import recall_score
recall_score_SVM=recall_score(Y_test, Y_pred, average='weighted')
# F1 SCORE
from sklearn.metrics import f1_score
f1_score_SVM=f1_score(Y_test, Y_pred, average='weighted')


# AUC + ROC CURVE
scores=classifier.decision_function(X_test)
from sklearn.metrics import roc_curve, auc 
fpr,tpr,threshold = roc_curve(Y_test, scores) 
roc_auc_SVM = auc(fpr,tpr) 

import matplotlib.pyplot as plt
plt.figure()
lw = 2
plt.figure(figsize=(10,10))
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc_SVM) 
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Support vector machine ROC curve (AUC = %0.4f)' % roc_auc_SVM,fontsize=18)
plt.legend(loc="lower right")
plt.show()




# Fitting KNN classifier
from sklearn.neighbors import *
classifier=KNeighborsClassifier(n_neighbors=8,weights='distance',algorithm='kd_tree')
classifier.fit(X_train, Y_train)
# Predicting the Test set results
Y_pred = classifier.predict(X_test)

# CONFUSION MATRIX
from sklearn.metrics import confusion_matrix
cm_KNN = confusion_matrix(Y_test, Y_pred)
# ACCURACY PROBABILITY
from sklearn.metrics import accuracy_score
accuracy_score_KNN=accuracy_score(Y_test, Y_pred)
# PRECISION 
from sklearn.metrics import precision_score
precision_score_KNN=precision_score(Y_test, Y_pred, average='weighted')
# RECALL
from sklearn.metrics import recall_score
recall_score_KNN=recall_score(Y_test, Y_pred, average='weighted')
# F1 SCORE
from sklearn.metrics import f1_score
f1_score_KNN=f1_score(Y_test, Y_pred, average='weighted')

# AUC + ROC CURVE
from sklearn.metrics import roc_curve, auc 
y_pred_proba =classifier.fit(X_train, Y_train).predict_proba(X_test)[:,1]
fpr,tpr,threshold = roc_curve(Y_test,y_pred_proba) 
roc_auc_KNN = auc(fpr,tpr) 

import matplotlib.pyplot as plt
plt.figure()
lw = 2
plt.figure(figsize=(10,10))
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc_KNN) 
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('KNN ROC curve (AUC = %0.4f)' % roc_auc_KNN,fontsize=18)
plt.legend(loc="lower right")
plt.show()

# run algorithms with different k value and choose the best according to accuracy
num=list(range(1,100))
accuracy_list=list(range(1,105))
for i in num:
    classifier=KNeighborsClassifier(n_neighbors=i,weights='distance',algorithm='kd_tree')
    classifier.fit(X_train, Y_train)
    # Predicting the Test set results
    Y_pred = classifier.predict(X_test)
    from sklearn.metrics import confusion_matrix
    cm_KNN = confusion_matrix(Y_test, Y_pred)
    # ACCURACY PROBABILITY
    from sklearn.metrics import accuracy_score
    accuracy_score_KNN=accuracy_score(Y_test, Y_pred)
    accuracy_list[i]=accuracy_score_KNN
    
accuracy_list=accuracy_list[1:99]
len(accuracy_list)
xxx=list(range(1,99))
accuracy_list.index(max(accuracy_list))    # best k value is:8

# draw picture to show accuracy change with k increasing
plt.figure()
plt.figure(figsize=(10,10))
plt.title('KNN model accuracy value with different k value')
plt.xlabel('k')
plt.ylabel('Accuracy')
plt.plot(xxx,accuracy_list)



# Fitting naive bayes 
from sklearn.naive_bayes import BernoulliNB
classifier = BernoulliNB(alpha=1)
classifier.fit(X_train, Y_train)
# Predicting the Test set results
Y_pred = classifier.predict(X_test)

# CONFUSION MATRIX
from sklearn.metrics import confusion_matrix
cm_NB = confusion_matrix(Y_test, Y_pred)
# ACCURACY PROBABILITY
from sklearn.metrics import accuracy_score
accuracy_score_NB=accuracy_score(Y_test, Y_pred)
# PRECISION 
from sklearn.metrics import precision_score
precision_score_NB=precision_score(Y_test, Y_pred, average='weighted')
# RECALL
from sklearn.metrics import recall_score
recall_score_NB=recall_score(Y_test, Y_pred, average='weighted')
# F1 SCORE
from sklearn.metrics import f1_score
f1_score_NB=f1_score(Y_test, Y_pred, average='weighted')

# AUC + ROC CURVE
from sklearn.metrics import roc_curve, auc 
y_pred_proba =classifier.predict_proba(X_test)[:,1]
fpr,tpr,threshold = roc_curve(Y_test,y_pred_proba) 
roc_auc_NB = auc(fpr,tpr) 

import matplotlib.pyplot as plt
plt.figure()
lw = 2
plt.figure(figsize=(10,10))
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc_NB) 
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Naive Bayes ROC curve (AUC = %0.4f)' % roc_auc_NB,fontsize=18)
plt.legend(loc="lower right")
plt.show()


#Fitting logistic regression
from sklearn.linear_model import LogisticRegression
classifier=LogisticRegression(penalty='l2')
classifier.fit(X_train, Y_train)
# Predicting the Test set results
Y_pred = classifier.predict(X_test)

# CONFUSION MATRIX
from sklearn.metrics import confusion_matrix
cm_LR = confusion_matrix(Y_test, Y_pred)
# ACCURACY PROBABILITY
from sklearn.metrics import accuracy_score
accuracy_score_LR=accuracy_score(Y_test, Y_pred)
# PRECISION 
from sklearn.metrics import precision_score
precision_score_LR=precision_score(Y_test, Y_pred, average='weighted')
# RECALL
from sklearn.metrics import recall_score
recall_score_LR=recall_score(Y_test, Y_pred, average='weighted')
# F1 SCORE
from sklearn.metrics import f1_score
f1_score_LR=f1_score(Y_test, Y_pred, average='weighted')


# AUC + ROC CURVE
scores=classifier.fit(X_train, Y_train).decision_function(X_test)
from sklearn.metrics import roc_curve, auc 
fpr,tpr,threshold = roc_curve(Y_test, scores) 
roc_auc_LR = auc(fpr,tpr) 

import matplotlib.pyplot as plt
plt.figure()
lw = 2
plt.figure(figsize=(10,10))
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc_LR) 
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Logistic Regression ROC curve (AUC = %0.4f)' % roc_auc_LR,fontsize=18)
plt.legend(loc="lower right")
plt.show()

